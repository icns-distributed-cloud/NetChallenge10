{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = ['LJSpeech-1.1', 'data']\n",
    "generated = ['generated_audio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/root/NetChallenge10')\n",
    "\n",
    "PATH = os.path.join(os.getcwd(), 'dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wav(label, path):\n",
    "    temp = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        file_path = os.path.join(path, file)\n",
    "\n",
    "        if(os.path.isdir(file_path)):\n",
    "            temp += search_wav(label, file_path)\n",
    "        elif(os.path.splitext(file_path)[-1] == '.wav'):\n",
    "            temp.append([label, file_path])\n",
    "    \n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_dataset_list\n",
    "label = 'real'\n",
    "real_dataset_list = []\n",
    "for folder in real:\n",
    "    real_dataset_list += search_wav(label, os.path.join(PATH, folder))\n",
    "\n",
    "# fake_dataset_list\n",
    "label = 'fake'\n",
    "fake_dataset_list = []\n",
    "for folder in generated:\n",
    "    fake_dataset_list += search_wav(label, os.path.join(PATH, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of real: 24018\n",
      "length of fake: 134266\n"
     ]
    }
   ],
   "source": [
    "print('length of real:', len(real_dataset_list))\n",
    "print('length of fake:', len(fake_dataset_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24018\n",
      "[['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_melgan_large/LJ010-0256_gen.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/gen_6358.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/generated/gen_5099.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_multi_band_melgan/LJ014-0243_gen.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_waveglow/LJ039-0061.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_waveglow/LJ050-0136.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_melgan_large/LJ013-0136_gen.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/ljspeech_full_band_melgan/LJ030-0122_gen.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/generated/gen_10996.wav'], ['fake', '/root/NetChallenge10/dataset/generated_audio/jsut_parallel_wavegan/BASIC5000_0158_gen.wav']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "balanced_fake_data_list = random.sample(fake_dataset_list, len(real_dataset_list))\n",
    "print(len(balanced_fake_data_list))\n",
    "print(balanced_fake_data_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all\n",
    "import json\n",
    "\n",
    "PATH = \"/root/NetChallenge10\"\n",
    "base_json = {\"data\":[]}\n",
    "\n",
    "for label, path in real_dataset_list+fake_dataset_list:\n",
    "    data = {\n",
    "        \"label\" : label,\n",
    "        \"wav\" : path\n",
    "    }\n",
    "\n",
    "    base_json['data'].append(data)\n",
    "\n",
    "# save preprocessed data\n",
    "os.makedirs(os.path.join(PATH, 'data'), exist_ok=True)\n",
    "with open(os.path.join(PATH, 'data', 'total_data.json'),'w') as j:\n",
    "    json.dump(base_json,j,ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all\n",
    "import json\n",
    "\n",
    "PATH = \"/root/NetChallenge10\"\n",
    "base_json = {\"data\":[]}\n",
    "\n",
    "for label, path in real_dataset_list+balanced_fake_data_list:\n",
    "    data = {\n",
    "        \"label\" : label,\n",
    "        \"wav\" : path\n",
    "    }\n",
    "\n",
    "    base_json['data'].append(data)\n",
    "\n",
    "# save preprocessed data\n",
    "os.makedirs(os.path.join(PATH, 'data'), exist_ok=True)\n",
    "with open(os.path.join(PATH, 'data', 'balanced_total_data.json'),'w') as j:\n",
    "    json.dump(base_json,j,ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'fake', 'wav': '/root/NetChallenge10/dataset/generated_audio/ljspeech_melgan_large/LJ040-0089_gen.wav'}\n",
      "{'label': 'real', 'wav': '/root/NetChallenge10/dataset/LJSpeech-1.1/LJSpeech-1.1/wavs/LJ002-0220.wav'}\n",
      "38428 9608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(base_json['data'], train_size=0.8, test_size=0.2, random_state=123, shuffle=True)\n",
    "print(train_data[0])\n",
    "print(test_data[0])\n",
    "print(len(train_data), len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터셋 저장\n",
      "Test 데이터셋 저장\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(PATH, 'data', 'train_preprocessed_data.json')\n",
    "print(\"Train 데이터셋 저장\")\n",
    "train_json = {'data' : train_data}\n",
    "with open(train_path,'w') as j:\n",
    "    json.dump(train_json,j,ensure_ascii=False, indent=4)\n",
    "\n",
    "test_path = os.path.join(PATH, 'data', 'test_preprocessed_data.json')\n",
    "print(\"Test 데이터셋 저장\")\n",
    "test_json = {'data' : test_data}\n",
    "with open(test_path,'w') as j:\n",
    "    json.dump(test_json,j,ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

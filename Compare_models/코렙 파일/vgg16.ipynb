{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 모델 추론"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1697113853921,"user":{"displayName":"김학호","userId":"04833138388719145173"},"user_tz":-540},"id":"-cRGk97Zt93h"},"outputs":[],"source":["import os\n","import json\n","import math\n","import numpy as np\n","import librosa\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from skimage.transform import resize\n","\n","\n","class Dataloader(Sequence):\n","    def __init__(self, Audios, labels, batch_size):\n","        self.Audios = Audios\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.num_classes = len(set(self.labels))\n","        self.indices = np.arange(len(self.labels))\n","\n","    def __len__(self):\n","        return math.ceil(len(self.labels)/self.batch_size)\n","    \n","    def __getitem__(self, idx):\n","        indices = self.indices[idx*self.batch_size : (idx+1)*self.batch_size]\n","        batch_x = [self.Audios[i] for i in indices]\n","        batch_audios = self.get_Audios(batch_x)\n","        batch_y = [self.labels[i] for i in indices]\n","        # 라벨을 원-핫 인코딩\n","        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n","        return np.array(batch_audios), np.array(batch_y)\n","    \n","    def get_Audios(self, path_list):\n","        # 오디오 데이터 로딩 및 전처리\n","        spectrograms = []\n","        for file_path in path_list:\n","            # 오디오 파일 로딩\n","            y, sr = librosa.load(file_path, sr=None)\n","            # 오디오 파일을 스펙트로그램으로 변환\n","            S = librosa.feature.melspectrogram(y=y, sr=sr)\n","            log_S = librosa.power_to_db(S, ref=np.max)\n","            \n","            # 스펙트로그램 이미지의 크기를 VGG16 입력 크기에 맞춤 (224, 224)\n","            log_S_resized = resize(log_S, (224, 224))\n","            \n","            # 채널 차원 추가 (VGG16은 RGB 이미지를 입력으로 받기 때문에 3차원이 필요)\n","            log_S_resized = np.stack([log_S_resized] * 3, axis=-1)\n","            \n","            spectrograms.append(log_S_resized) \n","\n","        return np.array(spectrograms)\n","\n","\n","\n","# JSON 파일 로딩 및 데이터 및 라벨 생성\n","with open('../test_dataset.json', 'r') as f:\n","    folder_label_mapping = json.load(f)\n","\n","file_paths = []\n","labels = []\n","\n","# 각 폴더 및 라벨에 대해\n","for file_path, label in folder_label_mapping.items():\n","    # 파일 확장자 확인하여 wav 파일만 처리\n","    if file_path.lower().endswith('.wav'):\n","        # 파일 경로 및 라벨 저장\n","        file_paths.append(file_path)\n","        labels.append(label)\n","\n","# 라벨을 정수로 변환 (만약 문자열 라벨을 사용하고 있다면)\n","unique_labels = sorted(set(labels))\n","label_to_int = {label: i for i, label in enumerate(unique_labels)}\n","labels = [label_to_int[label] for label in labels]\n","\n","# 라벨의 종류 수 계산\n","num_classes = len(set(labels))\n","\n","# 라벨 배열이 비어 있지 않은지 확인\n","if len(labels) == 0:\n","    raise ValueError(\"Labels array is empty. Check your data loading logic.\") \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Validation"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-14 06:44:36.611304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-14 06:44:36.611347: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-14 06:44:36.611364: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-14 06:44:36.617386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import os\n","import json\n","import math\n","import numpy as np\n","import librosa\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from skimage.transform import resize\n","\n","\n","class Dataloader(Sequence):\n","    def __init__(self, Audios, labels, batch_size):\n","        self.Audios = Audios\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.num_classes = len(set(self.labels))\n","        self.indices = np.arange(len(self.labels))\n","\n","    def __len__(self):\n","        return math.ceil(len(self.labels)/self.batch_size)\n","    \n","    def __getitem__(self, idx):\n","        indices = self.indices[idx*self.batch_size : (idx+1)*self.batch_size]\n","        batch_x = [self.Audios[i] for i in indices]\n","        batch_audios = self.get_Audios(batch_x)\n","        batch_y = [self.labels[i] for i in indices]\n","        # 라벨을 원-핫 인코딩\n","        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n","        return np.array(batch_audios), np.array(batch_y)\n","    \n","    def get_Audios(self, path_list):\n","        # 오디오 데이터 로딩 및 전처리\n","        spectrograms = []\n","        for file_path in path_list:\n","            # 오디오 파일 로딩\n","            y, sr = librosa.load(file_path, sr=None)\n","            # 오디오 파일을 스펙트로그램으로 변환\n","            S = librosa.feature.melspectrogram(y=y, sr=sr)\n","            log_S = librosa.power_to_db(S, ref=np.max)\n","            \n","            # 스펙트로그램 이미지의 크기를 VGG16 입력 크기에 맞춤 (224, 224)\n","            log_S_resized = resize(log_S, (224, 224))\n","            \n","            # 채널 차원 추가 (VGG16은 RGB 이미지를 입력으로 받기 때문에 3차원이 필요)\n","            log_S_resized = np.stack([log_S_resized] * 3, axis=-1)\n","            \n","            spectrograms.append(log_S_resized) \n","\n","        return np.array(spectrograms)\n","\n","\n","\n","# JSON 파일 로딩 및 데이터 및 라벨 생성\n","with open('../test_dataset.json', 'r') as f:\n","    folder_label_mapping = json.load(f)\n","\n","file_paths = []\n","labels = []\n","\n","# 각 폴더 및 라벨에 대해\n","for file_path, label in folder_label_mapping.items():\n","    # 파일 확장자 확인하여 wav 파일만 처리\n","    if file_path.lower().endswith('.wav'):\n","        # 파일 경로 및 라벨 저장\n","        file_paths.append(file_path)\n","        labels.append(label)\n","\n","Valid_dataloader = Dataloader(file_paths, labels, 16)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7Ev5Rfpl3kDJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-14 06:44:38.315261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.320512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.320817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.323012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.323192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.323322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.816429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.816638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.816647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-12-14 06:44:38.816834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-12-14 06:44:38.816854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9554 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n","2023-12-14 06:44:46.582091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n","2023-12-14 06:44:47.537142: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"]},{"name":"stdout","output_type":"stream","text":["  2/601 [..............................] - ETA: 35s - loss: 0.6933 - accuracy: 0.4062  "]},{"name":"stderr","output_type":"stream","text":["2023-12-14 06:44:48.454961: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"]},{"name":"stdout","output_type":"stream","text":["601/601 [==============================] - 595s 984ms/step - loss: 0.6932 - accuracy: 0.4933\n","loss=0.6931594610214233, acc=0.4932861328125\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","# 모델 로드\n","#model_path = '/root/Compare_models/vgg16_100epochs_model.h5'\n","model_path = './model/vgg16_50epochs_model_sum.h5'\n","model = load_model(model_path)\n","\n","# 모델 예측\n","loss, acc = model.evaluate(Valid_dataloader, )\n","print('loss={}, acc={}'.format(loss, acc))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 33/601 [>.............................] - ETA: 8:21"]},{"name":"stdout","output_type":"stream","text":["601/601 [==============================] - 496s 823ms/step\n"]}],"source":["pred = model.predict(Valid_dataloader)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," ...\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]]\n"]}],"source":["metric = tf.keras.metrics.F1Score(threshold=0.5)\n","y_true = to_categorical(Valid_dataloader.labels)\n","y_pred = pred\n","print(y_true)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.66067195, 0.        ], dtype=float32)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["metric.update_state(y_true, pred)\n","result = metric.result()\n","result.numpy()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["f1_score: 33.03%\n"]}],"source":["from sklearn.metrics import f1_score\n","\n","f1 = f1_score(np.argmax(y_true, axis=1), np.argmax(pred, axis=1), average='macro')\n","print(\"f1_score: %.2f%%\" % (f1 * 100.0))\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 ... 0 0 0]\n"]}],"source":["test = np.argmax(pred, axis=1)\n","print(test)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.500465, 0.499535],\n","       [0.500465, 0.499535],\n","       [0.500465, 0.499535],\n","       ...,\n","       [0.500465, 0.499535],\n","       [0.500465, 0.499535],\n","       [0.500465, 0.499535]], dtype=float32)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNDDGqJZRJeLbrZNDghne0/","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
